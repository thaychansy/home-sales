{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_KW73O2e3dw","outputId":"ee227662-fdad-4cab-b484-c2da54545254","executionInfo":{"status":"ok","timestamp":1728201049625,"user_tz":420,"elapsed":409637,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Waiting for headers] [Wa\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecte\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcont\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcont\r                                                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.8\r                                                                                                    \rIgn:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","\r                                                                                                    \r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80)]\r                                                                                 \rHit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","^C\n"]}],"source":["import os\n","# Find the latest version of spark 3.x  from https://downloads.apache.org/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.5.1'\n","spark_version = 'spark-3.5.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2XbWNf1Te5fM","executionInfo":{"status":"ok","timestamp":1728201057626,"user_tz":420,"elapsed":8003,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# Import packages\n","from pyspark.sql import SparkSession\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wOJqxG_RPSwp","executionInfo":{"status":"ok","timestamp":1728201057627,"user_tz":420,"elapsed":4,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RoljcJ7WPpnm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201071331,"user_tz":420,"elapsed":13707,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"44c668af-6fea-453d-ce83-8793858d3d73"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n","+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n","|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n","|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n","|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n","|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n","+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","\n"]}],"source":["# 2. Create a temporary view of the DataFrame.\n","# Add the file to SparkFiles\n","spark.sparkContext.addFile(url)\n","\n","# Read the CSV file into a DataFrame\n","df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), header=True, inferSchema=True)\n","\n","df.createOrReplaceTempView(\"home_sales\")\n","\n","# Verify that the view has been created by running a basic query\n","spark.sql(\"SELECT * FROM home_sales LIMIT 5\").show()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L6fkwOeOmqvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201074108,"user_tz":420,"elapsed":2779,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"7dd07933-e7ea-4fb7-c980-3502080c9935"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---------+\n","|year|avg_price|\n","+----+---------+\n","|2019| 300263.7|\n","|2020|298353.78|\n","|2021|301819.44|\n","|2022|296363.88|\n","+----+---------+\n","\n"]}],"source":["# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n","avg_price_4_bedroom = spark.sql(\"\"\"\n","    SELECT YEAR(date) AS year, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 4\n","    GROUP BY year\n","    ORDER BY year\n","\"\"\")\n","avg_price_4_bedroom.show()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"l8p_tUS8h8it","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201075389,"user_tz":420,"elapsed":1283,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"c2b46404-4ec2-4580-e144-2fcc4a35ea2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2015| 288770.3|\n","|      2013|295962.27|\n","|      2014|290852.27|\n","|      2012|293683.19|\n","|      2016|290555.07|\n","|      2010|292859.62|\n","|      2011|291117.47|\n","|      2017|292676.79|\n","+----------+---------+\n","\n"]}],"source":["# 4. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n","avg_price_3_bed_3_bath = spark.sql(\"\"\"\n","    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 3 AND bathrooms = 3\n","    GROUP BY date_built\n","    \"\"\")\n","avg_price_3_bed_3_bath.show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Y-Eytz64liDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201075977,"user_tz":420,"elapsed":590,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"86eb5473-cac4-4358-c13f-591f9e137623"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2015|297609.97|\n","|      2013|303676.79|\n","|      2014|298264.72|\n","|      2012|307539.97|\n","|      2016| 293965.1|\n","|      2010|285010.22|\n","|      2011|276553.81|\n","|      2017|280317.58|\n","+----------+---------+\n","\n"]}],"source":["# 5. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms, 3 bathrooms, with two floors,\n","# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n","avg_price_3_bed_3_bath_2_floors = spark.sql(\"\"\"\n","    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 3 AND bathrooms = 3 AND floors = 2 AND sqft_living >= 2000\n","    GROUP BY date_built\n","    \"\"\")\n","avg_price_3_bed_3_bath_2_floors.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUrfgOX1pCRd","outputId":"9e63a37a-4b59-4c5a-9ea8-eff34b9923cd","executionInfo":{"status":"ok","timestamp":1728201075978,"user_tz":420,"elapsed":7,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 0.0001366138458251953 seconds ---\n"]}],"source":["# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000? Order by descending view rating.\n","# Although this is a small dataset, determine the run time for this query.\n","\n","avg_price_view = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","    \"\"\")\n","\n","start_time = time.time()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KAhk3ZD2tFy8","executionInfo":{"status":"ok","timestamp":1728201076375,"user_tz":420,"elapsed":401,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 7. Cache the the temporary table home_sales.\n","spark.catalog.cacheTable(\"home_sales\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4opVhbvxtL-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201076375,"user_tz":420,"elapsed":6,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"09419c29-c309-43fb-a8a7-3a172f7c0498"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["# 8. Check if the table is cached.\n","spark.catalog.isCached('home_sales')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GnL46lwTSEk","outputId":"c68decec-d989-44a8-c446-a3c3a6fa0025","executionInfo":{"status":"ok","timestamp":1728201076375,"user_tz":420,"elapsed":5,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 0.00015807151794433594 seconds ---\n"]}],"source":["# 9. Using the cached data, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the uncached runtime.\n","avg_price_view = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","    \"\"\")\n","\n","\n","start_time = time.time()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Qm12WN9isHBR","executionInfo":{"status":"ok","timestamp":1728201082401,"user_tz":420,"elapsed":6029,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n","df.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(\"home_sales_partitioned\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"AZ7BgY61sRqY","executionInfo":{"status":"ok","timestamp":1728201082401,"user_tz":420,"elapsed":3,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 11. Read the parquet formatted data.\n","parquet_df = spark.read.parquet(\"home_sales_partitioned\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"J6MJkHfvVcvh","executionInfo":{"status":"ok","timestamp":1728201082402,"user_tz":420,"elapsed":4,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 12. Create a temporary table for the parquet data.\n","parquet_df.createOrReplaceTempView(\"home_sales_parquet\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_Vhb52rU1Sn","outputId":"3672c41c-4542-4df3-cf4f-5921f130d0ab","executionInfo":{"status":"ok","timestamp":1728201082711,"user_tz":420,"elapsed":312,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 9.632110595703125e-05 seconds ---\n"]}],"source":["# 13. Using the parquet DataFrame, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the cached runtime.\n","\n","avg_price_view = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales_parquet\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","    \"\"\")\n","\n","start_time = time.time()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"hjjYzQGjtbq8","executionInfo":{"status":"ok","timestamp":1728201082711,"user_tz":420,"elapsed":6,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 14. Uncache the home_sales temporary table.\n","spark.catalog.uncacheTable(\"home_sales\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Sy9NBvO7tlmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728201082711,"user_tz":420,"elapsed":5,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"a62f9c1a-3a84-4ecf-907e-598db24069c8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":17}],"source":["# 15. Check if the home_sales is no longer cached\n","spark.catalog.isCached(\"home_sales\")\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"nteract":{"version":"0.28.0"}},"nbformat":4,"nbformat_minor":0}