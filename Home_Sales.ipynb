{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_KW73O2e3dw","outputId":"b72674b1-5196-4afa-d804-3db28fb0f155","executionInfo":{"status":"ok","timestamp":1728755265340,"user_tz":420,"elapsed":38148,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.139.15.18)] [Connected to r2u.stat.i\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\r                                                                                                    \rHit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","\r                                                                                                    \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","\r                                                                                                    \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,602 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,449 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,160 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,326 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,387 kB]\n","Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,595 kB]\n","Fetched 18.8 MB in 6s (3,278 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}],"source":["import os\n","# Find the latest version of spark 3.x  from https://downloads.apache.org/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.5.1'\n","spark_version = 'spark-3.5.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2XbWNf1Te5fM","executionInfo":{"status":"ok","timestamp":1728755282901,"user_tz":420,"elapsed":17566,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# Import packages\n","from pyspark.sql import SparkSession\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wOJqxG_RPSwp","executionInfo":{"status":"ok","timestamp":1728755282901,"user_tz":420,"elapsed":26,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RoljcJ7WPpnm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755305027,"user_tz":420,"elapsed":22151,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"35a06076-1a28-4dfe-814e-8a76e4750f1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|                  id|      date|date_built| price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|\n","+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","|f8a53099-ba1c-47d...|2022-04-08|      2016|936923|       4|        3|       3167|   11733|     2|         1|  76|\n","|7530a2d8-1ae3-451...|2021-06-13|      2013|379628|       2|        2|       2235|   14384|     1|         0|  23|\n","|43de979c-0bf0-4c9...|2019-04-12|      2014|417866|       2|        2|       2127|   10575|     2|         0|   0|\n","|b672c137-b88c-48b...|2019-10-16|      2016|239895|       2|        2|       1631|   11149|     2|         0|   0|\n","|e0726d4d-d595-407...|2022-01-08|      2017|424418|       3|        2|       2249|   13878|     2|         0|   4|\n","+--------------------+----------+----------+------+--------+---------+-----------+--------+------+----------+----+\n","\n"]}],"source":["# 2. Create a temporary view of the DataFrame.\n","# Add the file to SparkFiles\n","spark.sparkContext.addFile(url)\n","\n","# Read the CSV file into a DataFrame\n","df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), header=True, inferSchema=True)\n","\n","df.createOrReplaceTempView(\"home_sales\")\n","\n","# Verify that the view has been created by running a basic query\n","spark.sql(\"SELECT * FROM home_sales LIMIT 5\").show()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"L6fkwOeOmqvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755308990,"user_tz":420,"elapsed":3987,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"f5c85d17-c2e7-42b7-ce9c-3e2543934365"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---------+\n","|year|avg_price|\n","+----+---------+\n","|2019| 300263.7|\n","|2020|298353.78|\n","|2021|301819.44|\n","|2022|296363.88|\n","+----+---------+\n","\n"]}],"source":["# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n","avg_price_4_bedroom = spark.sql(\"\"\"\n","    SELECT YEAR(date) AS year, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 4\n","    GROUP BY year\n","    ORDER BY year\n","\"\"\")\n","avg_price_4_bedroom.show()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"l8p_tUS8h8it","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755310182,"user_tz":420,"elapsed":1195,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"8ee16470-81b9-4a1f-98d4-f9d1a15d8071"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2015| 288770.3|\n","|      2013|295962.27|\n","|      2014|290852.27|\n","|      2012|293683.19|\n","|      2016|290555.07|\n","|      2010|292859.62|\n","|      2011|291117.47|\n","|      2017|292676.79|\n","+----------+---------+\n","\n"]}],"source":["# 4. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n","avg_price_3_bed_3_bath = spark.sql(\"\"\"\n","    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 3 AND bathrooms = 3\n","    GROUP BY date_built\n","    \"\"\")\n","avg_price_3_bed_3_bath.show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Y-Eytz64liDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755311126,"user_tz":420,"elapsed":947,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"b6c4026e-d8d3-475f-ac27-ffde2b431ed7"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|date_built|avg_price|\n","+----------+---------+\n","|      2015|297609.97|\n","|      2013|303676.79|\n","|      2014|298264.72|\n","|      2012|307539.97|\n","|      2016| 293965.1|\n","|      2010|285010.22|\n","|      2011|276553.81|\n","|      2017|280317.58|\n","+----------+---------+\n","\n"]}],"source":["# 5. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms, 3 bathrooms, with two floors,\n","# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n","avg_price_3_bed_3_bath_2_floors = spark.sql(\"\"\"\n","    SELECT date_built, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    WHERE bedrooms = 3 AND bathrooms = 3 AND floors = 2 AND sqft_living >= 2000\n","    GROUP BY date_built\n","    \"\"\")\n","avg_price_3_bed_3_bath_2_floors.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUrfgOX1pCRd","outputId":"c66db8d1-8c7b-4350-96d1-c6543d25336e","executionInfo":{"status":"ok","timestamp":1728755312068,"user_tz":420,"elapsed":945,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----------+\n","|view| avg_price|\n","+----+----------+\n","| 100| 1026669.5|\n","|  99|1061201.42|\n","|  98|1053739.33|\n","|  97|1129040.15|\n","|  96|1017815.92|\n","|  95| 1054325.6|\n","|  94| 1033536.2|\n","|  93|1026006.06|\n","|  92| 970402.55|\n","|  91|1137372.73|\n","|  90|1062654.16|\n","|  89|1107839.15|\n","|  88|1031719.35|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  85|1056336.74|\n","|  84|1117233.13|\n","|  83|1033965.93|\n","|  82| 1063498.0|\n","|  81|1053472.79|\n","+----+----------+\n","only showing top 20 rows\n","\n","Uncached query runtime: 0.9480197429656982 seconds\n"]}],"source":["# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000? Order by descending view rating.\n","# Although this is a small dataset, determine the run time for this query.\n","\n","# This query is useful to see how views affect home prices, with a condition for higher-priced homes\n","start_time_uncached = time.time()\n","avg_price_view = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\")\n","avg_price_view.show()\n","uncached_time = time.time() - start_time_uncached\n","print(f\"Uncached query runtime: {uncached_time} seconds\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KAhk3ZD2tFy8","executionInfo":{"status":"ok","timestamp":1728755312069,"user_tz":420,"elapsed":8,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 7. Cache the the temporary table home_sales.\n","spark.catalog.cacheTable(\"home_sales\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4opVhbvxtL-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755312069,"user_tz":420,"elapsed":7,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"0d286fad-eb1c-4855-a080-d03c159f6c48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Table cached: True\n"]}],"source":["# 8. Check if the table is cached.\n","is_cached = spark.catalog.isCached(\"home_sales\")\n","print(f\"Table cached: {is_cached}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GnL46lwTSEk","outputId":"897091de-9cb2-44b6-923a-79812cbd036e","executionInfo":{"status":"ok","timestamp":1728755314510,"user_tz":420,"elapsed":2447,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----------+\n","|view| avg_price|\n","+----+----------+\n","| 100| 1026669.5|\n","|  99|1061201.42|\n","|  98|1053739.33|\n","|  97|1129040.15|\n","|  96|1017815.92|\n","|  95| 1054325.6|\n","|  94| 1033536.2|\n","|  93|1026006.06|\n","|  92| 970402.55|\n","|  91|1137372.73|\n","|  90|1062654.16|\n","|  89|1107839.15|\n","|  88|1031719.35|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  85|1056336.74|\n","|  84|1117233.13|\n","|  83|1033965.93|\n","|  82| 1063498.0|\n","|  81|1053472.79|\n","+----+----------+\n","only showing top 20 rows\n","\n","Cached query runtime: 2.2813613414764404 seconds\n","Performance improvement from caching: -1.3333415985107422 seconds\n"]}],"source":["# 9. Using the cached data, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the uncached runtime.\n","\n","#Rerun the \"view\" rating query to compare cached vs. uncached performance\n","start_time_cached = time.time()\n","avg_price_view_cached = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\")\n","avg_price_view_cached.show()\n","cached_time = time.time() - start_time_cached\n","print(f\"Cached query runtime: {cached_time} seconds\")\n","\n","# Calculate and display the performance gain from caching\n","performance_gain = uncached_time - cached_time\n","print(f\"Performance improvement from caching: {performance_gain} seconds\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Qm12WN9isHBR","executionInfo":{"status":"ok","timestamp":1728755317500,"user_tz":420,"elapsed":2994,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n","df.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(\"home_sales_partitioned\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"AZ7BgY61sRqY","executionInfo":{"status":"ok","timestamp":1728755317500,"user_tz":420,"elapsed":22,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 11. Read the parquet formatted data.\n","parquet_df = spark.read.parquet(\"home_sales_partitioned\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"J6MJkHfvVcvh","executionInfo":{"status":"ok","timestamp":1728755317734,"user_tz":420,"elapsed":255,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 12. Create a temporary table for the parquet data.\n","# Load the partitioned Parquet data and create a temporary view\n","parquet_df = spark.read.parquet(\"home_sales_partitioned\")\n","parquet_df.createOrReplaceTempView(\"home_sales_parquet\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_Vhb52rU1Sn","outputId":"73ac0495-89aa-44ab-cda3-d37e45390459","executionInfo":{"status":"ok","timestamp":1728755319282,"user_tz":420,"elapsed":1551,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+----------+\n","|view| avg_price|\n","+----+----------+\n","| 100| 1026669.5|\n","|  99|1061201.42|\n","|  98|1053739.33|\n","|  97|1129040.15|\n","|  96|1017815.92|\n","|  95| 1054325.6|\n","|  94| 1033536.2|\n","|  93|1026006.06|\n","|  92| 970402.55|\n","|  91|1137372.73|\n","|  90|1062654.16|\n","|  89|1107839.15|\n","|  88|1031719.35|\n","|  87| 1072285.2|\n","|  86|1070444.25|\n","|  85|1056336.74|\n","|  84|1117233.13|\n","|  83|1033965.93|\n","|  82| 1063498.0|\n","|  81|1053472.79|\n","+----+----------+\n","only showing top 20 rows\n","\n","Partitioned data query runtime: 0.9693284034729004 seconds\n"]}],"source":["# 13. Using the parquet DataFrame, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the cached runtime.\n","\n","# Run the same query on the partitioned data and time it for comparison\n","start_time_partitioned = time.time()\n","avg_price_view_partitioned = spark.sql(\"\"\"\n","    SELECT view, ROUND(AVG(price), 2) AS avg_price\n","    FROM home_sales_parquet\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\")\n","avg_price_view_partitioned.show()\n","partitioned_time = time.time() - start_time_partitioned\n","print(f\"Partitioned data query runtime: {partitioned_time} seconds\")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"hjjYzQGjtbq8","executionInfo":{"status":"ok","timestamp":1728755319282,"user_tz":420,"elapsed":23,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}}},"outputs":[],"source":["# 14. Uncache the home_sales temporary table.\n","spark.catalog.uncacheTable(\"home_sales\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Sy9NBvO7tlmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728755319283,"user_tz":420,"elapsed":22,"user":{"displayName":"Thay Chansy","userId":"00803893884751578226"}},"outputId":"4e550bcc-7d6a-42dd-844a-ad3a246b2aff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Table cached after uncache operation: False\n"]}],"source":["# 15. Check if the home_sales is no longer cached\n","# Confirm that the table has been uncached\n","\n","is_uncached = spark.catalog.isCached(\"home_sales\")\n","print(f\"Table cached after uncache operation: {is_uncached}\")\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"nteract":{"version":"0.28.0"}},"nbformat":4,"nbformat_minor":0}